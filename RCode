#Load an R data frame.
#first of all set working directory

#install packages and load libraries

#install.packages("plyr") #Tools for Splitting, Applying and Combining Data
#install.packages("dplyr") #dplyr is a grammar of data manipulation,
#install.packages('ggplot2')
#install.packages('caret') #creating predictive model
#install.packages('rattle')
library(rattle)  #providing a graphical user interface
library(magrittr) # For the %>% and %<>% operators.
library(caret)
library(lattice)
library(ggplot2)
library(dplyr)
library(plyr)

#Load CSV file
Employee_Turnover <- read.csv("~/EmpTurnover.csv")
MYdataset <- Employee_Turnover

#data quality
str(MYdataset)
summary(MYdataset)
head(MYdataset)
sum(is.na(MYdataset)) #missing values

#initial look
StatusCount<- as.data.frame.matrix(MYdataset %>%
                                     group_by(STATUS_YEAR) %>%
                                     select(STATUS) %>%
                                     table())
StatusCount$TOTAL<-StatusCount$ACTIVE + StatusCount$TERMINATED
StatusCount$PercentTerminated <-StatusCount$TERMINATED/(StatusCount$TOTAL)*100
StatusCount
mean(StatusCount$PercentTerminated)

#plotting Business Unit to dertermine the ratio of Active to Terminated by status
ggplot() + geom_bar(aes(y = ..count..,x =as.factor(BUSINESS_UNIT),
                        fill = as.factor(STATUS)),
                    data=MYdataset,position = position_stack())


#just terminates
TerminatesData<- as.data.frame(MYdataset %>%
                                 filter(STATUS=="TERMINATED"))

#status_year by termtype_desc
ggplot() + geom_bar(aes(y = ..count..,x =as.factor(STATUS_YEAR),
                        fill = as.factor(termtype_desc)),
                    data=TerminatesData,position = position_stack())


#status_year by termreason_desc
ggplot() + geom_bar(aes(y = ..count..,x =as.factor(STATUS_YEAR),
                        fill = as.factor(termreason_desc)),
                    data=TerminatesData, position = position_stack())


#department_name by termreason_desc
ggplot() + geom_bar(aes(y = ..count..,x =as.factor(department_name),
                        fill = as.factor(termreason_desc)),
                    data=TerminatesData,position = position_stack())+
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))



#feature plot age and length of service
featurePlot(x=MYdataset[,6:7],y=MYdataset$STATUS,plot="density",
            auto.key = list(columns = 2))

#box plot age and length
featurePlot(x=MYdataset[,6:7],y=MYdataset$STATUS,plot="box",auto.key = list(columns = 2))

#######################################################################################################
#parition data

building <- TRUE
scoring  <- ! building

# A pre-defined value is used to reset the random seed so that results are repeatable.
crv$seed <- 42 

# Load an R data frame.
Employee_Turnover <- read.csv("~/EmpTurnover.csv")
MYdataset <- Employee_Turnover


#Create training and testing datasets
set.seed(crv$seed) 
MYnobs <- nrow(MYdataset) # 49653 observations 
MYnobs

#picking out from year 2006 to 2014 to train our model nrow (44637)/ Splitting dataset
MYsample <- MYtrain <- subset(MYdataset,STATUS_YEAR<=2014)

MYvalidate <- NULL

#test our model on 2015 data nrow(4906)
MYtest <- subset(MYdataset,STATUS_YEAR== 2015)


# The following variable selections have been noted / Feature Selection.
MYinput <- c("age", "length_of_service",    "gender_full",
               "STATUS_YEAR", "BUSINESS_UNIT")

MYnumeric <- c("age", "length_of_service", "STATUS_YEAR")

MYcategoric <- c("gender_full", "BUSINESS_UNIT")

MYtarget  <- "STATUS"
MYrisk    <- NULL
MYident   <- "EmployeeID"
MYignore  <- c("recorddate_key", "birthdate_key", "orighiredate_key", "terminationdate_key", 
               "city_name", "gender_short", "termreason_desc", "termtype_desc","department_name",
               "job_title", "store_name")
MYweights <- NULL

MYTrainingData<-MYtrain[c(MYinput, MYtarget)]
MYTestingData<-MYtest[c(MYinput, MYtarget)]

#checking the ratio of active to Terminated
table(MYTrainingData$STATUS)

                    ## modelling ##

# Classification Models
# Decision Tree 
# The 'rpart' package provides the 'rpart' function.
library(rattle)
library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.
set.seed(crv$seed)

# Build the Decision Tree model.
MYrpart <- rpart(STATUS ~ .,
                 data=MYTrainingData,
                 method="class",
                 parms=list(split="information"),
                 control=rpart.control(usesurrogate=0, 
                                       maxsurrogate=0))

# Generate a textual view of the Decision Tree model.
print(MYrpart)

MYpr <- predict(MYrpart, newdata=MYtest[c(MYinput, MYtarget)], type="class")
count(data.frame(MYpr))


# Plot the resulting Decision Tree. 
# We use the rpart.plot package.

fancyRpartPlot(MYrpart, main="Decision Tree MFG10YearTerminationData $ STATUS")

#install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(MYrpart, extra = 4)




#============================================================
# Rattle timestamp: 2016-03-25 18:21:29 x86_64-w64-mingw32
# Random Forest
# The 'randomForest' package provides the 'randomForest' function.

#install.packages("randomForest")
library(randomForest, quietly=TRUE)

# Build the Random Forest model.
set.seed(crv$seed)
MYrf <- randomForest::randomForest(STATUS ~ .,
                                   data=MYtrain[c(MYinput, MYtarget)],
                                   ntree=500,
                                   mtry=2,
                                   importance=TRUE,
                                   na.action=randomForest::na.roughfix,
                                   replace=FALSE)

# Generate textual output of 'Random Forest' model.
MYrf

library(pROC)

# The `pROC' package implements various AUC functions.
# Calculate the Area Under the Curve (AUC).
pROC::roc(MYrf$y, as.numeric(MYrf$predicted))

# Calculate the AUC Confidence Interval.
pROC::ci.auc(MYrf$y, as.numeric(MYrf$predicted))

# List the importance of the variables.
rn <- round(randomForest::importance(MYrf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 18.66 secs

#============================================================
# Rattle timestamp: 2016-03-25 18:22:22 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
install.packages("ada")
library(ada)

MYada <- ada::ada(STATUS ~ .,
                  data=MYtrain[c(MYinput, MYtarget)],
                  control=rpart::rpart.control(maxdepth=30,
                                               cp=0.010000,
                                               minsplit=20,
                                               xval=10),
                  iter=50)

# Print the results of the modelling.
print(MYada)
round(MYada$model$errs[MYada$iter,], 2)
cat('Variables actually used in tree construction:\n')

install.packages('listAdaVarsUsed')
library(listAdaVarsUsed)

print(sort(names(listAdaVarsUsed(MYada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(MYada))

# Time taken: 27.73 secs

#============================================================
# Rattle timestamp: 2016-03-25 18:22:56 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.
install.packages("kernlab")
library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
MYksvm <- ksvm(as.factor(STATUS) ~ .,
               data=MYtrain[c(MYinput, MYtarget)],
               kernel="rbfdot",
               prob.model=TRUE)

# Generate a textual view of the SVM model.

MYksvm

# Time taken: 42.91 secs

#============================================================
# Rattle timestamp: 2016-03-25 18:23:56 x86_64-w64-mingw32 

# Regression model 

# Build a Regression model.

MYglm <- glm(STATUS ~ .,
             data=MYtrain[c(MYinput, MYtarget)],
             family=binomial(link="logit"))

# Generate a textual view of the Linear model.

print(summary(MYglm))
cat(sprintf("Log likelihood: %.3f (%d df)\n",
            logLik(MYglm)[1],
            attr(logLik(MYglm), "df")))
cat(sprintf("Null/Residual deviance difference: %.3f (%d df)\n",
            MYglm$null.deviance-MYglm$deviance,
            MYglm$df.null-MYglm$df.residual))
cat(sprintf("Chi-square p-value: %.8f\n",
            dchisq(MYglm$null.deviance-MYglm$deviance,
                   MYglm$df.null-MYglm$df.residual)))
cat(sprintf("Pseudo R-Square (optimistic): %.8f\n",
            cor(MYglm$y, MYglm$fitted.values)))
cat('\n==== ANOVA ====\n\n')
print(anova(MYglm, test="Chisq"))
cat("\n")



